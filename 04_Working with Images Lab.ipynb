{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecac9c20-e9eb-4b83-b9b3-edd1ec32d57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your imports here\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647c583f",
   "metadata": {},
   "source": [
    "opencv байхгүй бол суулгах OPEN COMPUTER VISION library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f65c3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f409693-729b-4a8a-b69e-767deb80b648",
   "metadata": {},
   "source": [
    "# Working with Images Lab\n",
    "## Information retrieval, preprocessing, and feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a328e6-f43f-40c3-abf3-cb650ff59141",
   "metadata": {},
   "source": [
    "In this lab, you'll work with images of felines (cats), which have been classified according to their taxonomy. Each subfolder contains images of a particular species. The dataset is located [here](https://www.kaggle.com/datasets/datahmifitb/felis-taxonomy-image-classification) but it's also provided to you in the `data/` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2930cdea-105b-4f27-b28f-30323036b6c1",
   "metadata": {},
   "source": [
    "### Problem 1. Some exploration (1 point)\n",
    "How many types of cats are there? How many images do we have of each? What is a typical image size? Are there any outliers in size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72d6fbdb-37b4-4ce4-a3fa-65954c377539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat Types and Image Counts:\n",
      "african-wildcat: 83 images\n",
      "blackfoot-cat: 74 images\n",
      "chinese-mountain-cat: 36 images\n",
      "domestic-cat: 58 images\n",
      "european-wildcat: 53 images\n",
      "jungle-cat: 80 images\n",
      "sand-cat: 67 images\n",
      "\n",
      "Typical Image Size (Mean): 251861.33 pixels\n",
      "Median Image Size: 50350.00 pixels\n",
      "Number of Outlier Images: 10\n"
     ]
    }
   ],
   "source": [
    "path = 'data'\n",
    "\n",
    "cat_types = {}  \n",
    "image_sizes = []  \n",
    "\n",
    "with os.scandir(path) as entries:\n",
    "    for entry in entries:\n",
    "        if entry.is_dir():\n",
    "            folder_path = entry.path \n",
    "            files = [f for f in os.listdir(folder_path) if f.lower().endswith(('jpg', 'jpeg', 'png'))]  \n",
    "            \n",
    "            cat_types[entry.name] = len(files)  \n",
    "            \n",
    "            for file in files:\n",
    "                img_path = os.path.join(folder_path, file)\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    height, width, _ = img.shape\n",
    "                    image_sizes.append(height * width) \n",
    "                else:\n",
    "                    print(f\"Error reading {img_path}\")\n",
    "\n",
    "print(\"Cat Types and Image Counts:\")\n",
    "for cat, count in cat_types.items():\n",
    "    print(f\"{cat}: {count} images\")\n",
    "\n",
    "if image_sizes:\n",
    "    mean_size = np.mean(image_sizes)\n",
    "    median_size = np.median(image_sizes)\n",
    "    std_dev = np.std(image_sizes)\n",
    "\n",
    "    outliers = [size for size in image_sizes if size > mean_size + 2 * std_dev]\n",
    "\n",
    "    print(f\"\\nTypical Image Size (Mean): {mean_size:.2f} pixels\")\n",
    "    print(f\"Median Image Size: {median_size:.2f} pixels\")\n",
    "    print(f\"Number of Outlier Images: {len(outliers)}\")\n",
    "else:\n",
    "    print(\"\\nNo images found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a54a788-a46a-4683-b78e-6e9c9e25c46d",
   "metadata": {},
   "source": [
    "### Problem 2. Duplicat(e)s (1 point)\n",
    "Find a way to filter out (remove) identical images. I would recommnend using file hashes, but there are many approaches. Keep in mind that during file saving, recompression, etc., a lot of artifacts can change the file content (bytes), but not visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82a8920c-1237-488e-8267-c1f6cadbdb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Duplicate removal complete.\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "from imagehash import phash\n",
    "from PIL import Image\n",
    "\n",
    "md5_hashes = set()\n",
    "phash_dict = {}\n",
    "\n",
    "# Function to calculate MD5 hash of a file\n",
    "def get_md5(file_path):\n",
    "    hasher = hashlib.md5()\n",
    "    with open(file_path, 'rb') as f:\n",
    "        buf = f.read()\n",
    "        hasher.update(buf)\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "# Function to calculate perceptual hash (pHash)\n",
    "def get_phash(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        return phash(img)  # Returns a unique hash based on image content\n",
    "    except Exception as e:\n",
    "        print(f\"Error hashing {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Iterate over all folders\n",
    "for root, _, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('jpg', 'jpeg', 'png')):\n",
    "            img_path = os.path.join(root, file)\n",
    "\n",
    "            # Check for exact duplicates using MD5\n",
    "            md5 = get_md5(img_path)\n",
    "            if md5 in md5_hashes:\n",
    "                print(f\"Removing exact duplicate: {img_path}\")\n",
    "                os.remove(img_path)\n",
    "                continue  # Skip to the next file\n",
    "            md5_hashes.add(md5)\n",
    "\n",
    "            # Check for near duplicates using pHash\n",
    "            img_phash = get_phash(img_path)\n",
    "            if img_phash:\n",
    "                # Compare with existing hashes (Hamming distance < 5 means similar)\n",
    "                if any(img_phash - existing_hash < 5 for existing_hash in phash_dict.values()):\n",
    "                    print(f\"Removing near-duplicate: {img_path}\")\n",
    "                    os.remove(img_path)\n",
    "                    continue\n",
    "                phash_dict[img_path] = img_phash\n",
    "\n",
    "print(\"✅ Duplicate removal complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918359ba-8d97-42c4-82ec-975931ec7fb9",
   "metadata": {},
   "source": [
    "### Problem 3. Loading a model (2 points)\n",
    "Find a suitable, trained convolutional neural network classifier. I recommend `ResNet50` as it's small enough to run well on any machine and powerful enough to make reasonable predictions. Most ready-made classifiers have been trained for 1000 classes.\n",
    "\n",
    "You'll need to install libraries and possibly tinker with configurations for this task. When you're done, display the total number of layers and the total number of parameters. For ResNet50, you should expect around 50 layers and 25M parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c7d40ed-2f0e-42ea-82cc-e3427c84d061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef6b32-db23-4616-b497-e78a41a1d487",
   "metadata": {},
   "source": [
    "### Problem 4. Prepare the images (1 point)\n",
    "You'll need to prepare the images for passing to the model. To do so, they have to be resized to the same dimensions. Most available models have a specific requirement for sizes. You may need to do additional preprocessing, depending on the model requirements. These requirements should be easily available in the model documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87300cdc-b8b0-4fae-83dc-b0b15639ec71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat Types and Image Counts:\n",
      "african-wildcat: 83 images\n",
      "blackfoot-cat: 74 images\n",
      "chinese-mountain-cat: 36 images\n",
      "domestic-cat: 58 images\n",
      "european-wildcat: 53 images\n",
      "jungle-cat: 80 images\n",
      "sand-cat: 67 images\n",
      "\n",
      "Typical Image Size (Mean): 151018.66 pixels\n",
      "Median Image Size: 50176.00 pixels\n",
      "Number of Outlier Images: 11\n",
      "\n",
      "Prepared 451 images for training.\n"
     ]
    }
   ],
   "source": [
    "target_size = (224, 224)\n",
    "\n",
    "prepared_data = []\n",
    "\n",
    "with os.scandir(path) as entries:\n",
    "    for entry in entries:\n",
    "        if entry.is_dir():\n",
    "            label = entry.name  # Subfolder name is the label\n",
    "            folder_path = entry.path \n",
    "            files = [f for f in os.listdir(folder_path) if f.lower().endswith(('jpg', 'jpeg', 'png'))]  \n",
    "            \n",
    "            cat_types[label] = len(files)  \n",
    "            \n",
    "            for file in files:\n",
    "                img_path = os.path.join(folder_path, file)\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    # Convert from BGR to RGB\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    # Resize the image to the target size\n",
    "                    img = cv2.resize(img, target_size)\n",
    "                    height, width, _ = img.shape\n",
    "                    image_sizes.append(height * width)\n",
    "                    # Append the processed image along with its label\n",
    "                    prepared_data.append((img, label))\n",
    "                else:\n",
    "                    print(f\"Error reading {img_path}\")\n",
    "\n",
    "print(\"Cat Types and Image Counts:\")\n",
    "for cat, count in cat_types.items():\n",
    "    print(f\"{cat}: {count} images\")\n",
    "\n",
    "if image_sizes:\n",
    "    mean_size = np.mean(image_sizes)\n",
    "    median_size = np.median(image_sizes)\n",
    "    std_dev = np.std(image_sizes)\n",
    "\n",
    "    outliers = [size for size in image_sizes if size > mean_size + 2 * std_dev]\n",
    "\n",
    "    print(f\"\\nTypical Image Size (Mean): {mean_size:.2f} pixels\")\n",
    "    print(f\"Median Image Size: {median_size:.2f} pixels\")\n",
    "    print(f\"Number of Outlier Images: {len(outliers)}\")\n",
    "else:\n",
    "    print(\"\\nNo images found.\")\n",
    "\n",
    "print(f\"\\nPrepared {len(prepared_data)} images for training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ade4b3-62ac-4f4e-aa02-3c65dc9ab3d9",
   "metadata": {},
   "source": [
    "### Problem 5. Load the images efficiently (1 point)\n",
    "Now that you've seen how to prepare the images for passing to the model... find a way to do it efficiently. Instead of loading the entire dataset in the RAM, read the images in batches (e.g. 4 images at a time). The goal is to read these, preprocess them, maybe save the preprocessed results in RAM.\n",
    "\n",
    "If you've already done this in one of the previous problems, just skip this one. You'll get your point for it.\n",
    "\n",
    "\\* Even better, save the preprocessed image arrays (they will not be valid .jpg file) as separate files, so you can load them \"lazily\" in the following steps. This is a very common optimization to work with large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b660eb-ab73-42f1-8f57-34fff32d6111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f62f557e-fae0-42f1-aa3b-4402a9be05d2",
   "metadata": {},
   "source": [
    "### Problem 6. Predictions (1 point)\n",
    "Finally, you're ready to get into the meat of the problem. Obtain predictions from your model and evaluate them. This will likely involve manual work to decide how the returned classes relate to the original ones.\n",
    "\n",
    "Create a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) to evaluate the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96856dec-a4b6-4930-a237-61ec399017d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5020f81e-721f-4882-83eb-80379f7a20ac",
   "metadata": {},
   "source": [
    "### Problem 7. Grayscale (1 point)\n",
    "Converting the images to grayscale should affect the classification negatively, as we lose some of the color information.\n",
    "\n",
    "Find a way to preprocess the images to grayscale (using what you already have in Problem 4 and 5), pass them to the model, and compare the classification results to the previous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24421ab0-f30f-447c-a496-80d9aa00cbe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e585e663-2f06-4562-8bea-504b3d583c66",
   "metadata": {},
   "source": [
    "### Problem 8. Deep image features (1 point)\n",
    "Find a way to extract one-dimensional vectors (features) for each (non-grayscale) image, using your model. This is typically done by \"short-circuiting\" the model output to be an intermediate layer, while keeping the input the same. \n",
    "\n",
    "In case the outputs (also called feature maps) have different shapes, you can flatten them in different ways. Try to not create huge vectors; the goal is to have a relatively short sequence of numbers which describes each image.\n",
    "\n",
    "You may find a tutorial like [this](https://towardsdatascience.com/exploring-feature-extraction-with-cnns-345125cefc9a) pretty useful but note your implementation will depend on what model (and framework) you've decided to use.\n",
    "\n",
    "It's a good idea to save these as one or more files, so you'll spare yourself a ton of preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71347edf-a13b-4683-beb2-af0a093a0cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9bd0ab0-910a-4dad-9383-011e7d7616e1",
   "metadata": {},
   "source": [
    "### Problem 9. Putting deep image features to use (1 points)\n",
    "Try to find similar images, using a similarity metric on the features you got in the previous problem. Two good metrics are `mean squared error` and `cosine similarity`. How do they work? Can you spot images that look too similar? Can you explain why?\n",
    "\n",
    "\\* If we were to take Fourier features (in a similar manner, these should be a vector of about the same length), how do they compare to the deep features; i.e., which features are better to \"catch\" similar images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5276ec7b-7736-4508-99bd-29516464e3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba16d333-35f0-4b3d-b4b8-3d86cf5cd8b4",
   "metadata": {},
   "source": [
    "### * Problem 10. Explore, predict, and evaluate further\n",
    "You can do a ton of things here, at your desire. For example, how does masking different areas of the image affect classification - a method known as **saliency map** ([info](https://en.wikipedia.org/wiki/Saliency_map))? Can we detect objects? Can we significantly reduce the number of features (keeping the quality) that we get? Can we reliably train a model to predict our own classes? We'll look into these in detail in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f1a50-ea32-41ce-9215-77a80c300dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
