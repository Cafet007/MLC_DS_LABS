{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb8c5630-11b2-41b9-98a2-f67d6cebc323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sergelen.n\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sergelen.n\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sergelen.n\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\sergelen.n\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "  \n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0375379c-19e4-4e50-9f63-5c74cf81ece5",
   "metadata": {},
   "source": [
    "# Working with Text Lab\n",
    "## Information retrieval, preprocessing, and feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92edf71-988c-4e95-b17f-987095e9246a",
   "metadata": {},
   "source": [
    "In this lab, you'll be looking at and exploring European restaurant reviews. The dataset is rather tiny, but that's just because it has to run on any machine. In real life, just like with images, texts can be several terabytes long.\n",
    "\n",
    "The dataset is located [here](https://www.kaggle.com/datasets/gorororororo23/european-restaurant-reviews) and as always, it's been provided to you in the `data/` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888cf2cf-1cd7-4538-a7a2-462e80b1df99",
   "metadata": {},
   "source": [
    "### Problem 1. Read the dataset (1 point)\n",
    "Read the dataset, get acquainted with it. Ensure the data is valid before you proceed.\n",
    "\n",
    "How many observations are there? Which country is the most represented? What time range does the dataset represent?\n",
    "\n",
    "Is the sample balanced in terms of restaurants, i.e., do you have an equal number of reviews for each one? Most importantly, is the dataset balanced in terms of **sentiment**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f281dc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_column_names(df):\n",
    "    def to_snake_case(name):\n",
    "        name = name.lower()\n",
    "        name = re.sub(r'[^a-z0-9]', '_', name)\n",
    "        name = re.sub(r'_+', '_', name)\n",
    "        name = name.strip('_')\n",
    "        return name\n",
    "    \n",
    "    df.columns = [to_snake_case(col) for col in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b87ca4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Standardized column names:\n",
      "['country', 'restaurant_name', 'sentiment', 'review_title', 'review_date', 'review']\n",
      "==============================\n",
      "Dataset Info:\n",
      "==============================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1502 entries, 0 to 1501\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   country          1502 non-null   object\n",
      " 1   restaurant_name  1502 non-null   object\n",
      " 2   sentiment        1502 non-null   object\n",
      " 3   review_title     1502 non-null   object\n",
      " 4   review_date      1502 non-null   object\n",
      " 5   review           1502 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 70.5+ KB\n",
      "None\n",
      "==============================\n",
      "First 5 Rows:\n",
      "==============================\n",
      "  country            restaurant_name sentiment  \\\n",
      "0  France  The Frog at Bercy Village  Negative   \n",
      "1  France  The Frog at Bercy Village  Negative   \n",
      "2  France  The Frog at Bercy Village  Negative   \n",
      "3  France  The Frog at Bercy Village  Negative   \n",
      "4  France  The Frog at Bercy Village  Negative   \n",
      "\n",
      "                                review_title review_date  \\\n",
      "0                               Rude manager  May 2024 •   \n",
      "1                       A big disappointment  Feb 2024 •   \n",
      "2               Pretty Place with Bland Food  Nov 2023 •   \n",
      "3   Great service and wine but inedible food  Mar 2023 •   \n",
      "4  Avoid- Worst meal in Rome - possibly ever  Nov 2022 •   \n",
      "\n",
      "                                              review  \n",
      "0  The manager became agressive when I said the c...  \n",
      "1  I ordered a beef fillet ask to be done medium,...  \n",
      "2  This is an attractive venue with welcoming, al...  \n",
      "3  Sadly I  used the high TripAdvisor rating too ...  \n",
      "4  From the start this meal was bad- especially g...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/european_restaurant_reviews.csv')\n",
    "df = standardize_column_names(df)\n",
    "\n",
    "\n",
    "print(\"=\" * 30)\n",
    "print(\"Standardized column names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(\"=\" * 30)\n",
    "print(\"Dataset Info:\")\n",
    "print(\"=\" * 30)\n",
    "print(df.info())\n",
    "\n",
    "print(\"=\" * 30)\n",
    "print(\"First 5 Rows:\")\n",
    "print(\"=\" * 30)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75557250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset time range: 2010-09-01 00:00:00 to 2024-07-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "df['review_date'] = df['review_date'].str.replace(r'\\bSept\\b', 'Sep', regex=True)\n",
    "\n",
    "df['review_date'] = df['review_date'].str.extract(r'(\\w+\\s\\d{4})')\n",
    "\n",
    "df['review_date'] = pd.to_datetime(df['review_date'], format='%b %Y', errors='coerce')\n",
    "\n",
    "date_range = (df['review_date'].min(), df['review_date'].max())\n",
    "print(f\"Dataset time range: {date_range[0]} to {date_range[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "596f1cf0-acfe-4e05-a953-6a2fc1ea2463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Number of observations: 1502\n",
      "==============================\n",
      "Most represented country: France\n",
      "==============================\n",
      "Restaurant Review Counts:\n",
      "count      7.000000\n",
      "mean     214.571429\n",
      "std      153.396933\n",
      "min       81.000000\n",
      "25%      117.500000\n",
      "50%      146.000000\n",
      "75%      264.000000\n",
      "max      512.000000\n",
      "Name: count, dtype: float64\n",
      "==============================\n",
      "Sentiment Distribution:\n",
      "sentiment\n",
      "Positive    0.823569\n",
      "Negative    0.176431\n",
      "Name: proportion, dtype: float64\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "num_observations = len(df)\n",
    "print(\"=\" * 30)\n",
    "print(f\"Number of observations: {num_observations}\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "most_represented_country = df['country'].value_counts().idxmax()\n",
    "print(f\"Most represented country: {most_represented_country}\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "restaurant_counts = df['restaurant_name'].value_counts()\n",
    "print(\"Restaurant Review Counts:\")\n",
    "print(restaurant_counts.describe())\n",
    "print(\"=\" * 30)\n",
    "\n",
    "sentiment_counts = df['sentiment'].value_counts(normalize=True)\n",
    "print(\"Sentiment Distribution:\")\n",
    "print(sentiment_counts)\n",
    "print(\"=\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a55576-cd3c-4451-b5c8-6a51356a7386",
   "metadata": {},
   "source": [
    "### Problem 2. Getting acquainted with reviews (1 point)\n",
    "Are positive comments typically shorter or longer? Try to define a good, robust metric for \"length\" of a text; it's not necessary just the character count. Can you explain your findings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97901e74-6093-4274-966a-da73ec3a5961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Statistics:\n",
      "          review_word_count                                                   \\\n",
      "                      count        mean         std   min   25%   50%    75%   \n",
      "sentiment                                                                      \n",
      "Negative              265.0  140.573585  131.759636  13.0  55.0  95.0  177.0   \n",
      "Positive             1237.0   50.183508   38.741043   2.0  25.0  37.0   61.0   \n",
      "\n",
      "                 review_unique_word_count             ... review_char_count  \\\n",
      "             max                    count       mean  ...               75%   \n",
      "sentiment                                             ...                     \n",
      "Negative   646.0                    265.0  93.626415  ...             983.0   \n",
      "Positive   340.0                   1237.0  40.817300  ...             340.0   \n",
      "\n",
      "                  review_avg_word_length                                \\\n",
      "              max                  count      mean       std       min   \n",
      "sentiment                                                                \n",
      "Negative   3679.0                  265.0  5.471901  0.326906  4.844828   \n",
      "Positive   2020.0                 1237.0  5.702581  0.512583  4.520000   \n",
      "\n",
      "                                                   \n",
      "                25%       50%       75%       max  \n",
      "sentiment                                          \n",
      "Negative   5.229630  5.454545  5.628571  7.000000  \n",
      "Positive   5.359375  5.634409  5.956522  8.692308  \n",
      "\n",
      "[2 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "df['review_word_count'] = df['review'].apply(lambda x: len(str(x).split()))\n",
    "df['review_unique_word_count'] = df['review'].apply(lambda x: len(set(str(x).split())))\n",
    "df['review_char_count'] = df['review'].apply(lambda x: len(str(x)))\n",
    "df['review_avg_word_length'] = df['review_char_count'] / df['review_word_count']\n",
    "\n",
    "sentiment_stats = df.groupby('sentiment')[['review_word_count', 'review_unique_word_count', 'review_char_count', 'review_avg_word_length']].describe()\n",
    "print(\"Sentiment Statistics:\")\n",
    "print(sentiment_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c440fff-c079-464c-b97d-fffbf3d65baf",
   "metadata": {},
   "source": [
    "### Problem 3. Preprocess the review content (2 points)\n",
    "You'll likely need to do this while working on the problems below, but try to synthesize (and document!) your preprocessing here. Your tasks will revolve around words and their connection to sentiment. While preprocessing, keep in mind the domain (restaurant reviews) and the task (sentiment analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7114fcf9-c63a-41b2-9ff9-591a15d2ebe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [manager, became, agressive, said, carbonara, ...\n",
      "1    [ordered, beef, fillet, ask, done, medium, got...\n",
      "2    [attractive, venue, welcoming, albeit, somewha...\n",
      "3    [sadly, used, high, tripadvisor, rating, liter...\n",
      "4    [start, meal, bad, especially, given, price, v...\n",
      "Name: clean_review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['clean_review'] = df['review'].str.lower()\n",
    "df['clean_review'] = df['clean_review'].apply(lambda x: re.sub(r'[^a-z\\s]', '', x))\n",
    "\n",
    "df['clean_review'] = df['clean_review'].apply(word_tokenize)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['clean_review'] = df['clean_review'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['clean_review'] = df['clean_review'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "print(df['clean_review'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8532af-2411-4d71-a003-0813be3f98de",
   "metadata": {},
   "source": [
    "### Problem 3. Top words (1 point)\n",
    "Use a simple word tokenization and count the top 10 words in positive reviews; then the top 10 words in negative reviews*. Once again, try to define what \"top\" words means. Describe and document your process. Explain your results.\n",
    "\n",
    "\\* Okay, you may want to see top N words (with $N \\ge 10$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faaa6dd4-251e-4e32-9137-cc6c984726be",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "df['clean_review'] = df['clean_review'].apply(lambda x: [word for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790ae91f-2def-41bc-8861-49fc5467b335",
   "metadata": {},
   "source": [
    "### Problem 4. Review titles (2 point)\n",
    "How do the top words you found in the last problem correlate to the review titles? Do the top 10 words (for each sentiment) appear in the titles at all? Do reviews which contain one or more of the top words have the same words in their titles?\n",
    "\n",
    "Does the title of a comment present a good summary of its content? That is, are the titles descriptive, or are they simply meant to catch the attention of the reader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "330b83f1-060e-47ae-8035-0b8372eed8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews with top positive words in the title: 393\n",
      "Number of reviews with top negative words in the title: 38\n"
     ]
    }
   ],
   "source": [
    "top_positive_words = ['delicious', 'great', 'amazing', 'love', 'best']\n",
    "top_negative_words = ['bad', 'terrible', 'disappointed', 'horrible', 'worst']\n",
    "\n",
    "def check_title_for_top_words(row, top_words):\n",
    "    title_words = row['review_title'].lower().split()\n",
    "    return any(word in title_words for word in top_words)\n",
    "\n",
    "df['top_positive_in_title'] = df.apply(lambda x: check_title_for_top_words(x, top_positive_words), axis=1)\n",
    "df['top_negative_in_title'] = df.apply(lambda x: check_title_for_top_words(x, top_negative_words), axis=1)\n",
    "\n",
    "positive_in_titles = df['top_positive_in_title'].sum()\n",
    "negative_in_titles = df['top_negative_in_title'].sum()\n",
    "\n",
    "print(f\"Number of reviews with top positive words in the title: {positive_in_titles}\")\n",
    "print(f\"Number of reviews with top negative words in the title: {negative_in_titles}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a0aa94-23e4-4db1-a780-cd1bd3abb411",
   "metadata": {},
   "source": [
    "### Problem 5. Bag of words (1 point)\n",
    "Based on your findings so far, come up with a good set of settings (hyperparameters) for a bag-of-words model for review titles and contents. It's easiest to treat them separately (so, create two models); but you may also think about a unified representation. I find the simplest way of concatenating the title and content too simplistic to be useful, as it doesn't allow you to treat the title differently (e.g., by giving it more weight).\n",
    "\n",
    "The documentation for `CountVectorizer` is [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html). Familiarize yourself with all settings; try out different combinations and come up with a final model; or rather - two models :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ce7892f-cb37-48d3-83fc-0ccb56c2bb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100' 'abbie' 'absolutely' 'absolutely best' 'ad' 'ad hoc' 'affordable'\n",
      " 'albeit' 'albeit overpriced' 'amazing' 'amazing dinner'\n",
      " 'amazing experience' 'amazing food' 'amazing place' 'amazing restaurant'\n",
      " 'ambiance' 'ambience' 'american' 'anniversary' 'apology']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "title_vectorizer = CountVectorizer(\n",
    "    ngram_range=(1, 2),      \n",
    "    stop_words='english',   \n",
    "    max_features=1000,       \n",
    "    min_df=3                \n",
    ")\n",
    "\n",
    "X_title = title_vectorizer.fit_transform(df['review_title'])\n",
    "\n",
    "print(title_vectorizer.get_feature_names_out()[:20])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a337ce0f-2afe-422f-8e9d-beddd5635093",
   "metadata": {},
   "source": [
    "### Problem 6. Deep sentiment analysis models (1 point)\n",
    "Find a suitable model for sentiment analysis in English. Without modifying, training, or fine-tuning the model, make it predict all contents (or better, combinations of titles and contents, if you can). Meaure the accuracy of the model compared to the `sentiment` column in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f74e8f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of sentiment analysis: 96.01%\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", truncation=True, max_length=512)\n",
    "df['combined_review'] = df['review_title'] + \" \" + df['review']\n",
    "predictions = df['combined_review'].apply(lambda x: sentiment_analyzer(x[:512])[0]['label'])\n",
    "df['predicted_sentiment'] = predictions.map({'POSITIVE': 'Positive', 'NEGATIVE': 'Negative'})\n",
    "accuracy = (df['predicted_sentiment'] == df['sentiment']).mean()\n",
    "print(f\"Accuracy of sentiment analysis: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773d804d-9c83-48ec-be2b-8564d73d908c",
   "metadata": {},
   "source": [
    "### Problem 7. Deep features (embeddings) (1 point)\n",
    "Use the same model to perform feature extraction on the review contents (or contents + titles) instead of direct predictions. You should already be familiar how to do that from your work on images.\n",
    "\n",
    "Use the cosine similarity between texts to try to cluster them. Are there \"similar\" reviews (you'll need to find a way to measure similarity) across different restaurants? Are customers generally in agreement for the same restaurant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f732c764-2ef0-4da2-a662-f8cd7b684245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c79a585f-1dad-469a-a2ae-31d3981b9e1b",
   "metadata": {},
   "source": [
    "### \\* Problem 8. Explore and model at will\n",
    "In this lab, we focused on preprocessing and feature extraction and we didn't really have a chance to train (or compare) models. The dataset is maybe too small to be conclusive, but feel free to play around with ready-made models, and train your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e90732-4d96-4692-8588-b9429430a98b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
